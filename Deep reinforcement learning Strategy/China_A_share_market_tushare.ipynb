{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-G6H6HsRTFLn",
   "metadata": {
    "id": "-G6H6HsRTFLn"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/China_A_share_market_tushare.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ShYRMdBTFLp",
   "metadata": {
    "id": "3ShYRMdBTFLp"
   },
   "source": [
    "## Quantitative trading in China A stock market with FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBU3DdPFTFLp",
   "metadata": {
    "id": "pBU3DdPFTFLp"
   },
   "source": [
    "Install FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51W37k2_TFLq",
   "metadata": {
    "id": "51W37k2_TFLq"
   },
   "outputs": [],
   "source": [
    "# !pip install wrds\n",
    "# !pip install swig\n",
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ZmuaPTCTFLr",
   "metadata": {
    "id": "9ZmuaPTCTFLr"
   },
   "source": [
    "Install other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q6T3o9yTTFLr",
   "metadata": {
    "id": "q6T3o9yTTFLr"
   },
   "outputs": [],
   "source": [
    "# !pip install stockstats\n",
    "# !pip install tushare\n",
    "# #install talib\n",
    "# !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "# !tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "# import os\n",
    "# os.chdir('ta-lib') \n",
    "# !./configure --prefix=/usr\n",
    "# !make\n",
    "# !make install\n",
    "# #!sudo make install # Sometimes it need root \n",
    "# os.chdir('../')\n",
    "# !pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DrReji1OTFLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrReji1OTFLr",
    "outputId": "325c38e3-ca71-4b58-e0be-104e15011fe2"
   },
   "outputs": [],
   "source": [
    "# %cd /\n",
    "# !git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "# %cd /FinRL-Meta/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "C-MYxgpJTMGP",
   "metadata": {
    "id": "C-MYxgpJTMGP"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Vx_hcZwgTKQp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx_hcZwgTKQp",
    "outputId": "d6b36801-3064-4251-aadd-2396cb03ad5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "from IPython import display\n",
    "\n",
    "# display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config \n",
    "from meta.data_processor import DataProcessor, DataSource\n",
    "# from main import check_and_make_directories \n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter \n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv \n",
    "from agents.stablebaselines3_models import DRLAgent \n",
    "import os \n",
    "from typing import List \n",
    "from argparse import ArgumentParser \n",
    "from meta import config \n",
    "from meta.config_tickers import DOW_30_TICKER \n",
    "from meta.config import ( DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE, ERL_PARAMS, RLlib_PARAMS, SAC_PARAMS, ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL, )\n",
    "\n",
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "FRQz2ptSTjPJ",
   "metadata": {
    "id": "FRQz2ptSTjPJ"
   },
   "source": [
    "## Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pmttRZWWTXcd",
   "metadata": {
    "id": "pmttRZWWTXcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' \n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\") \n",
    "'''\n",
    "\n",
    "# check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n",
    "if not os.path.exists(\"./datasets\"): \n",
    "  os.makedirs(\"./datasets\") \n",
    "if not os.path.exists(\"./trained_models\"): \n",
    "  os.makedirs(\"./trained_models\") \n",
    "if not os.path.exists(\"./tensorboard_log\"): \n",
    "  os.makedirs(\"./tensorboard_log\") \n",
    "if not os.path.exists(\"./results\"): \n",
    "  os.makedirs(\"./results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94s2JtmxTuLq",
   "metadata": {
    "id": "94s2JtmxTuLq"
   },
   "source": [
    "## Download data, cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "xpPTz-xDTovy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpPTz-xDTovy",
    "outputId": "40df5f90-6211-452c-ee63-2dc2c849b370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSource.akshare successfully connected\n"
     ]
    }
   ],
   "source": [
    "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
    "\n",
    "TRAIN_START_DATE = '2015-01-01' \n",
    "TRAIN_END_DATE= '2019-08-01' \n",
    "TRADE_START_DATE = '2019-08-01' \n",
    "TRADE_END_DATE = '2020-01-03'\n",
    "\n",
    "TIME_INTERVAL = \"daily\" \n",
    "kwargs = {} \n",
    "# kwargs['token'] = '27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5' \n",
    "p = DataProcessor(data_source=DataSource.akshare, start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "svZh2OT0T7PG",
   "metadata": {
    "id": "svZh2OT0T7PG"
   },
   "source": [
    "### Download and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "v_PzruLIT3D1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_PzruLIT3D1",
    "outputId": "fa4b9030-f8ff-41a3-abef-77be4f9d37ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:13<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['日期', '股票代码', '开盘', '收盘', '最高', '最低', '成交量', '成交额', '振幅', '涨跌幅', '涨跌额',\n",
      "       '换手率', 'tic'],\n",
      "      dtype='object')\n",
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    }
   ],
   "source": [
    "p.download_data(ticker_list=ticker_list)\n",
    "p.clean_data()\n",
    "p.fillna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "tsHu-XT_T_vQ",
   "metadata": {
    "id": "tsHu-XT_T_vQ"
   },
   "source": [
    "### Add technical indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "VfniyyQQT3nq",
   "metadata": {
    "id": "VfniyyQQT3nq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n"
     ]
    }
   ],
   "source": [
    "p.add_technical_indicator(config.INDICATORS) \n",
    "p.fillna()\n",
    "\n",
    "#print(f\"p.dataframe: {p.dataframe}\")\n",
    "# p.dataframe[\"date\"] = p.dataframe[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b352493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"china_data.pkl\", mode=\"wb\") as f:\n",
    "    pickle.dump(p, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cKZk3jGuUR34",
   "metadata": {
    "id": "cKZk3jGuUR34"
   },
   "source": [
    "## Split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d08837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"china_data.pkl\", mode=\"rb\") as f:\n",
    "    p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "SuKbrwflUVeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuKbrwflUVeU",
    "outputId": "7596367b-670d-4d6c-b439-033075d87589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE) \n",
    "\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ONAnSMBUWyu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ONAnSMBUWyu",
    "outputId": "5bdf45d0-7689-4d31-dfa6-cbcbe8e64827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tic.unique(): ['600000' '600009' '600016' '600028' '600030' '600031' '600036' '600050'\n",
      " '600104' '600196' '600276' '600309' '600519' '600547' '600570']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.tic.unique(): {train.tic.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "BXF8hYDvUXfv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXF8hYDvUXfv",
    "outputId": "a08ebe19-0107-4e31-c6df-816c846aa3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.head():       tic        time  index   open   high    low  close  adjusted_close  \\\n",
      "0  600000  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
      "0  600009  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
      "0  600016  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
      "0  600028  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
      "0  600030  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
      "\n",
      "      volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
      "0  3306272.0 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
      "0   198117.0 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
      "0  4851684.0 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
      "0  8190902.0 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
      "0  6376269.0  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
      "\n",
      "        dx_30  close_30_sma  close_60_sma  \n",
      "0   20.602022       15.8150       15.8150  \n",
      "0  100.000000       20.2000       20.2000  \n",
      "0  100.000000       10.4775       10.4775  \n",
      "0   64.602490        7.0425        7.0425  \n",
      "0  100.000000       35.1925       35.1925  \n"
     ]
    }
   ],
   "source": [
    "print(f\"train.head(): {train.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "CnwNoBG5UXSQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnwNoBG5UXSQ",
    "outputId": "3bcf1c7a-e9de-4b92-fc7e-069904d9e6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (16695, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "joNhXi_ZUXId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joNhXi_ZUXId",
    "outputId": "460b9763-6b0f-4976-f772-4a9a7cda2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique()) \n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1 \n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "le09273cUmzH",
   "metadata": {
    "id": "le09273cUmzH"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc40a269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tic', 'time', 'index', 'open', 'high', 'low', 'close',\n",
       "       'adjusted_close', 'volume', 'macd', 'boll_ub', 'boll_lb', 'rsi_30',\n",
       "       'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "Npwpqkr7UpFF",
   "metadata": {
    "id": "Npwpqkr7UpFF"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"buy_cost_pct\": 6.87e-5,\n",
    "    \"sell_cost_pct\": 1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\": True,\n",
    "    \"hundred_each_trade\": True \n",
    "}\n",
    "\n",
    "train[\"date\"] = train[\"time\"]\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1POZL3nUyDY",
   "metadata": {
    "id": "f1POZL3nUyDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() \n",
    "\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "QkY8sVWhU6PH",
   "metadata": {
    "id": "QkY8sVWhU6PH"
   },
   "source": [
    "### DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dLjEviBhUzuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLjEviBhUzuc",
    "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_3\n",
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1603481.71\n",
      "total_reward: 603481.71\n",
      "total_cost: 12310.29\n",
      "total_trades: 1346\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1562122.59\n",
      "total_reward: 562122.59\n",
      "total_cost: 130.41\n",
      "total_trades: 40\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1663692.64\n",
      "total_reward: 663692.64\n",
      "total_cost: 130.36\n",
      "total_trades: 39\n",
      "Sharpe: 0.564\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1572253.59\n",
      "total_reward: 572253.59\n",
      "total_cost: 130.41\n",
      "total_trades: 37\n",
      "Sharpe: 0.505\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 105        |\n",
      "|    time_elapsed    | 42         |\n",
      "|    total_timesteps | 4452       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 426        |\n",
      "|    critic_loss     | 675        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 4351       |\n",
      "|    reward          | -0.1572244 |\n",
      "-----------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1544550.69\n",
      "total_reward: 544550.69\n",
      "total_cost: 130.31\n",
      "total_trades: 37\n",
      "Sharpe: 0.491\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1587844.58\n",
      "total_reward: 587844.58\n",
      "total_cost: 130.42\n",
      "total_trades: 38\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1613607.58\n",
      "total_reward: 613607.58\n",
      "total_cost: 130.42\n",
      "total_trades: 38\n",
      "Sharpe: 0.527\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1573486.54\n",
      "total_reward: 573486.54\n",
      "total_cost: 130.46\n",
      "total_trades: 42\n",
      "Sharpe: 0.513\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 103        |\n",
      "|    time_elapsed    | 86         |\n",
      "|    total_timesteps | 8904       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 371        |\n",
      "|    critic_loss     | 19.2       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8803       |\n",
      "|    reward          | -0.1573429 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", } \n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300])) \n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "\n",
    "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ALJ1gqVmVEiU",
   "metadata": {
    "id": "ALJ1gqVmVEiU"
   },
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2F5qCGnNUzm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2F5qCGnNUzm7",
    "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_3\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 387          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | -81.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -3.29        |\n",
      "|    reward             | -0.017931068 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.211        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 392         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | -2.27       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -2.69       |\n",
      "|    reward             | -0.00803173 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.0209      |\n",
      "---------------------------------------\n",
      "Episode: 11\n",
      "day: 1112, episode: 11\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1486259.63\n",
      "total_reward: 486259.63\n",
      "total_cost: 133744.37\n",
      "total_trades: 11283\n",
      "Sharpe: 0.484\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 394          |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | -24.4        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -1.33        |\n",
      "|    reward             | -0.018711615 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.024        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 398         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | -0.0038     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.00597     |\n",
      "|    reward             | -0.02180166 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000785    |\n",
      "---------------------------------------\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2714100.07\n",
      "total_reward: 1714100.07\n",
      "total_cost: 175477.93\n",
      "total_trades: 11772\n",
      "Sharpe: 1.004\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -24.5        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 11           |\n",
      "|    reward             | -0.012623618 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.315        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 397         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | -0.01559753 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 8.91e-05    |\n",
      "---------------------------------------\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1739282.99\n",
      "total_reward: 739282.99\n",
      "total_cost: 137881.01\n",
      "total_trades: 11150\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 398         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -15.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | -0.01592644 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.017       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | -305         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -6.66        |\n",
      "|    reward             | -0.105618015 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.19         |\n",
      "----------------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1040383.41\n",
      "total_reward: 40383.41\n",
      "total_cost: 94145.59\n",
      "total_trades: 10304\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | -493         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 2.75         |\n",
      "|    reward             | -0.023344344 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.0232       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 398         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | -17.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | -0.06831311 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.00623     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | -0.899       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.013005774 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00372      |\n",
      "----------------------------------------\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 901252.15\n",
      "total_reward: -98747.85\n",
      "total_cost: 71538.85\n",
      "total_trades: 8819\n",
      "Sharpe: 0.012\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 399           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | -9.5          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.876         |\n",
      "|    reward             | -0.0017063572 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.00229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 399           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.6         |\n",
      "|    explained_variance | -2.46         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.407         |\n",
      "|    reward             | -0.0016135215 |\n",
      "|    std                | 1.16          |\n",
      "|    value_loss         | 0.000457      |\n",
      "-----------------------------------------\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1020446.06\n",
      "total_reward: 20446.06\n",
      "total_cost: 77603.94\n",
      "total_trades: 8951\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 399          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | -3.67        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -10.4        |\n",
      "|    reward             | -0.011529062 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.188        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 398           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | -0.132        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 0.00269       |\n",
      "|    reward             | -0.0076632746 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 0.000184      |\n",
      "-----------------------------------------\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1054705.85\n",
      "total_reward: 54705.85\n",
      "total_cost: 56751.15\n",
      "total_trades: 7700\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 398           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -1.8          |\n",
      "|    reward             | -0.0069967327 |\n",
      "|    std                | 1.27          |\n",
      "|    value_loss         | 0.00533       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 398           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.1         |\n",
      "|    explained_variance | -92.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -2.25         |\n",
      "|    reward             | -0.0061101713 |\n",
      "|    std                | 1.29          |\n",
      "|    value_loss         | 0.0198        |\n",
      "-----------------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 661851.12\n",
      "total_reward: -338148.88\n",
      "total_cost: 42959.88\n",
      "total_trades: 6460\n",
      "Sharpe: -0.355\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 399           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.117         |\n",
      "|    reward             | -0.0016010051 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 2.42e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.8         |\n",
      "|    explained_variance | -607          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -0.932        |\n",
      "|    reward             | -0.0031697643 |\n",
      "|    std                | 1.35          |\n",
      "|    value_loss         | 0.00209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.2         |\n",
      "|    explained_variance | 0.0371        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.364         |\n",
      "|    reward             | -0.0007705327 |\n",
      "|    std                | 1.39          |\n",
      "|    value_loss         | 0.000216      |\n",
      "-----------------------------------------\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 735577.46\n",
      "total_reward: -264422.54\n",
      "total_cost: 23919.54\n",
      "total_trades: 4661\n",
      "Sharpe: -0.329\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 398            |\n",
      "|    iterations         | 2100           |\n",
      "|    time_elapsed       | 26             |\n",
      "|    total_timesteps    | 10500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -26.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2099           |\n",
      "|    policy_loss        | -0.0439        |\n",
      "|    reward             | -0.00074998883 |\n",
      "|    std                | 1.44           |\n",
      "|    value_loss         | 1.02e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 398          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | -0.013277243 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 3.54e-05     |\n",
      "----------------------------------------\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 877759.42\n",
      "total_reward: -122240.58\n",
      "total_cost: 21317.58\n",
      "total_trades: 4100\n",
      "Sharpe: -0.626\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | -0.0511       |\n",
      "|    reward             | -0.0014372658 |\n",
      "|    std                | 1.6           |\n",
      "|    value_loss         | 3.37e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.9         |\n",
      "|    explained_variance | -4.75         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 0.141         |\n",
      "|    reward             | -0.0001411098 |\n",
      "|    std                | 1.66          |\n",
      "|    value_loss         | 3.25e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 709923.31\n",
      "total_reward: -290076.69\n",
      "total_cost: 20894.69\n",
      "total_trades: 3969\n",
      "Sharpe: -0.480\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 397            |\n",
      "|    iterations         | 2500           |\n",
      "|    time_elapsed       | 31             |\n",
      "|    total_timesteps    | 12500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.5          |\n",
      "|    explained_variance | -1.33          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2499           |\n",
      "|    policy_loss        | 0.17           |\n",
      "|    reward             | -0.00055476796 |\n",
      "|    std                | 1.73           |\n",
      "|    value_loss         | 4.7e-05        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 32            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30           |\n",
      "|    explained_variance | 0.476         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -1.24         |\n",
      "|    reward             | -0.0009539209 |\n",
      "|    std                | 1.78          |\n",
      "|    value_loss         | 0.00236       |\n",
      "-----------------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 663455.96\n",
      "total_reward: -336544.04\n",
      "total_cost: 21907.04\n",
      "total_trades: 4291\n",
      "Sharpe: -0.431\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | 0.153         |\n",
      "|    reward             | -0.0014805297 |\n",
      "|    std                | 1.83          |\n",
      "|    value_loss         | 2.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | -12.9        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.772        |\n",
      "|    reward             | -0.082883395 |\n",
      "|    std                | 1.9          |\n",
      "|    value_loss         | 0.00095      |\n",
      "----------------------------------------\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 746155.22\n",
      "total_reward: -253844.78\n",
      "total_cost: 24219.78\n",
      "total_trades: 4254\n",
      "Sharpe: -0.367\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 397            |\n",
      "|    iterations         | 2900           |\n",
      "|    time_elapsed       | 36             |\n",
      "|    total_timesteps    | 14500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2899           |\n",
      "|    policy_loss        | -0.0719        |\n",
      "|    reward             | -0.00010132563 |\n",
      "|    std                | 1.96           |\n",
      "|    value_loss         | 1.97e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 37            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | -29.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.7           |\n",
      "|    reward             | -0.0004792512 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 0.000917      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.1         |\n",
      "|    explained_variance | -10.5         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | 1.21          |\n",
      "|    reward             | -0.0015908348 |\n",
      "|    std                | 2.06          |\n",
      "|    value_loss         | 0.0014        |\n",
      "-----------------------------------------\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 675520.87\n",
      "total_reward: -324479.13\n",
      "total_cost: 23790.13\n",
      "total_trades: 3975\n",
      "Sharpe: -0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | -77.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | -0.0376       |\n",
      "|    reward             | -0.0004388817 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | -18.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.316        |\n",
      "|    reward             | -4.12887e-05 |\n",
      "|    std                | 2.2          |\n",
      "|    value_loss         | 0.000159     |\n",
      "----------------------------------------\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 691325.80\n",
      "total_reward: -308674.20\n",
      "total_cost: 22630.20\n",
      "total_trades: 3716\n",
      "Sharpe: -0.413\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 397            |\n",
      "|    iterations         | 3400           |\n",
      "|    time_elapsed       | 42             |\n",
      "|    total_timesteps    | 17000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -33.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3399           |\n",
      "|    policy_loss        | -0.1           |\n",
      "|    reward             | -0.00042978648 |\n",
      "|    std                | 2.29           |\n",
      "|    value_loss         | 9.23e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.3        |\n",
      "|    explained_variance | -86.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | -0.288       |\n",
      "|    reward             | -0.004890139 |\n",
      "|    std                | 2.38         |\n",
      "|    value_loss         | 0.000336     |\n",
      "----------------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 705464.57\n",
      "total_reward: -294535.43\n",
      "total_cost: 23626.43\n",
      "total_trades: 3694\n",
      "Sharpe: -0.488\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 45            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | 0.194         |\n",
      "|    reward             | -0.0035986546 |\n",
      "|    std                | 2.45          |\n",
      "|    value_loss         | 3.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.3        |\n",
      "|    explained_variance | -3.19        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.0527       |\n",
      "|    reward             | -0.000897708 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 694141.63\n",
      "total_reward: -305858.37\n",
      "total_cost: 30150.37\n",
      "total_trades: 4346\n",
      "Sharpe: -0.393\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.132       |\n",
      "|    reward             | -0.004484805 |\n",
      "|    std                | 2.62         |\n",
      "|    value_loss         | 2.03e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 49            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.3         |\n",
      "|    explained_variance | -18.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 1.09          |\n",
      "|    reward             | -0.0013621536 |\n",
      "|    std                | 2.73          |\n",
      "|    value_loss         | 0.00125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 50            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.9         |\n",
      "|    explained_variance | 0.682         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | 0.0278        |\n",
      "|    reward             | -0.0019666578 |\n",
      "|    std                | 2.83          |\n",
      "|    value_loss         | 5.51e-06      |\n",
      "-----------------------------------------\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 760439.05\n",
      "total_reward: -239560.95\n",
      "total_cost: 35769.95\n",
      "total_trades: 5103\n",
      "Sharpe: -0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 51            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.4         |\n",
      "|    explained_variance | -31           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | -0.147        |\n",
      "|    reward             | -0.0029751933 |\n",
      "|    std                | 2.93          |\n",
      "|    value_loss         | 0.00012       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.8         |\n",
      "|    explained_variance | 0.0416        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -1.32         |\n",
      "|    reward             | -0.0012098432 |\n",
      "|    std                | 3.02          |\n",
      "|    value_loss         | 0.00172       |\n",
      "-----------------------------------------\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 678318.69\n",
      "total_reward: -321681.31\n",
      "total_cost: 36692.31\n",
      "total_trades: 5267\n",
      "Sharpe: -0.432\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.171        |\n",
      "|    reward             | -0.004455343 |\n",
      "|    std                | 3.15         |\n",
      "|    value_loss         | 2.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 55            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | 0.31          |\n",
      "|    reward             | -0.0022616126 |\n",
      "|    std                | 3.3           |\n",
      "|    value_loss         | 7.97e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 966575.53\n",
      "total_reward: -33424.47\n",
      "total_cost: 38721.47\n",
      "total_trades: 4926\n",
      "Sharpe: -0.291\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 56            |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | -0.0112       |\n",
      "|    reward             | -0.0012666595 |\n",
      "|    std                | 3.47          |\n",
      "|    value_loss         | 8.02e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 397          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.005115329 |\n",
      "|    std                | 3.67         |\n",
      "|    value_loss         | 3.46e-05     |\n",
      "----------------------------------------\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 989541.70\n",
      "total_reward: -10458.30\n",
      "total_cost: 35739.30\n",
      "total_trades: 4907\n",
      "Sharpe: -0.060\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 59            |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | -0.0808       |\n",
      "|    reward             | -0.0038379368 |\n",
      "|    std                | 3.89          |\n",
      "|    value_loss         | 5.84e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 60            |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | 0.314         |\n",
      "|    reward             | -0.0043886164 |\n",
      "|    std                | 4.13          |\n",
      "|    value_loss         | 6.45e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 840756.08\n",
      "total_reward: -159243.92\n",
      "total_cost: 37341.92\n",
      "total_trades: 5020\n",
      "Sharpe: -0.421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 397           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 61            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.078        |\n",
      "|    reward             | -0.0006095786 |\n",
      "|    std                | 4.36          |\n",
      "|    value_loss         | 4.39e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.0508       |\n",
      "|    reward             | -0.002431874 |\n",
      "|    std                | 4.58         |\n",
      "|    value_loss         | 2.65e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 64            |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.8         |\n",
      "|    explained_variance | -289          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | -2.03         |\n",
      "|    reward             | -0.0074670454 |\n",
      "|    std                | 4.81          |\n",
      "|    value_loss         | 0.00289       |\n",
      "-----------------------------------------\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 795351.03\n",
      "total_reward: -204648.97\n",
      "total_cost: 42347.97\n",
      "total_trades: 5229\n",
      "Sharpe: -0.397\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 396         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.1       |\n",
      "|    explained_variance | -35.9       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -3.25       |\n",
      "|    reward             | -0.00421709 |\n",
      "|    std                | 4.92        |\n",
      "|    value_loss         | 0.00483     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 5300          |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 26500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.5         |\n",
      "|    explained_variance | -0.00991      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5299          |\n",
      "|    policy_loss        | -0.468        |\n",
      "|    reward             | -0.0069296393 |\n",
      "|    std                | 5.04          |\n",
      "|    value_loss         | 0.000385      |\n",
      "-----------------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 635043.15\n",
      "total_reward: -364956.85\n",
      "total_cost: 42349.85\n",
      "total_trades: 5373\n",
      "Sharpe: -0.466\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.0392       |\n",
      "|    reward             | -0.002843006 |\n",
      "|    std                | 5.2          |\n",
      "|    value_loss         | 2.53e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 69            |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.4         |\n",
      "|    explained_variance | -0.435        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | 0.333         |\n",
      "|    reward             | -0.0049986974 |\n",
      "|    std                | 5.36          |\n",
      "|    value_loss         | 0.00173       |\n",
      "-----------------------------------------\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 701055.21\n",
      "total_reward: -298944.79\n",
      "total_cost: 39895.79\n",
      "total_trades: 5095\n",
      "Sharpe: -0.434\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 70            |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 0.161         |\n",
      "|    reward             | -0.0010046517 |\n",
      "|    std                | 5.52          |\n",
      "|    value_loss         | 1.37e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 396            |\n",
      "|    iterations         | 5700           |\n",
      "|    time_elapsed       | 71             |\n",
      "|    total_timesteps    | 28500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -47.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 5699           |\n",
      "|    policy_loss        | 0.311          |\n",
      "|    reward             | -0.00078945333 |\n",
      "|    std                | 5.74           |\n",
      "|    value_loss         | 5.43e-05       |\n",
      "------------------------------------------\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 900979.16\n",
      "total_reward: -99020.84\n",
      "total_cost: 42389.84\n",
      "total_trades: 5057\n",
      "Sharpe: -0.278\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 5800          |\n",
      "|    time_elapsed       | 73            |\n",
      "|    total_timesteps    | 29000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5799          |\n",
      "|    policy_loss        | -1.34         |\n",
      "|    reward             | -0.0029736084 |\n",
      "|    std                | 5.99          |\n",
      "|    value_loss         | 0.000732      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -48.7        |\n",
      "|    explained_variance | -2.36        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.336        |\n",
      "|    reward             | -0.007268414 |\n",
      "|    std                | 6.25         |\n",
      "|    value_loss         | 5.01e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 6000          |\n",
      "|    time_elapsed       | 75            |\n",
      "|    total_timesteps    | 30000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.1         |\n",
      "|    explained_variance | -13.2         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5999          |\n",
      "|    policy_loss        | -0.474        |\n",
      "|    reward             | -0.0028345534 |\n",
      "|    std                | 6.45          |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 659326.25\n",
      "total_reward: -340673.75\n",
      "total_cost: 41848.75\n",
      "total_trades: 5205\n",
      "Sharpe: -0.476\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 6100          |\n",
      "|    time_elapsed       | 76            |\n",
      "|    total_timesteps    | 30500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6099          |\n",
      "|    policy_loss        | 0.24          |\n",
      "|    reward             | -0.0008964982 |\n",
      "|    std                | 6.69          |\n",
      "|    value_loss         | 3.28e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 78            |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -50.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.408         |\n",
      "|    reward             | -0.0007755439 |\n",
      "|    std                | 7.01          |\n",
      "|    value_loss         | 8.28e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 786517.50\n",
      "total_reward: -213482.50\n",
      "total_cost: 44889.50\n",
      "total_trades: 5239\n",
      "Sharpe: -0.553\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 79           |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.355        |\n",
      "|    reward             | -0.008117571 |\n",
      "|    std                | 7.34         |\n",
      "|    value_loss         | 5.33e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -51.9        |\n",
      "|    explained_variance | -6.33        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.757       |\n",
      "|    reward             | -0.010051715 |\n",
      "|    std                | 7.75         |\n",
      "|    value_loss         | 0.00272      |\n",
      "----------------------------------------\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 747301.46\n",
      "total_reward: -252698.54\n",
      "total_cost: 47656.54\n",
      "total_trades: 5291\n",
      "Sharpe: -0.692\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.0123      |\n",
      "|    reward             | -0.009239666 |\n",
      "|    std                | 8.14         |\n",
      "|    value_loss         | 2.43e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 83            |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.4         |\n",
      "|    explained_variance | 0.112         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -3.32         |\n",
      "|    reward             | -0.0009579585 |\n",
      "|    std                | 8.58          |\n",
      "|    value_loss         | 0.00469       |\n",
      "-----------------------------------------\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 723172.90\n",
      "total_reward: -276827.10\n",
      "total_cost: 47404.10\n",
      "total_trades: 5571\n",
      "Sharpe: -0.426\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 84            |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | 0.261         |\n",
      "|    reward             | -0.0026053537 |\n",
      "|    std                | 8.89          |\n",
      "|    value_loss         | 3.04e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.427        |\n",
      "|    reward             | -0.004034022 |\n",
      "|    std                | 9.28         |\n",
      "|    value_loss         | 7.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 87           |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -55.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -0.444       |\n",
      "|    reward             | -0.010079589 |\n",
      "|    std                | 9.75         |\n",
      "|    value_loss         | 7.18e-05     |\n",
      "----------------------------------------\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 810173.24\n",
      "total_reward: -189826.76\n",
      "total_cost: 62512.76\n",
      "total_trades: 6273\n",
      "Sharpe: -0.456\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 396          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56          |\n",
      "|    explained_variance | -72.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.994        |\n",
      "|    reward             | -0.002555075 |\n",
      "|    std                | 10.2         |\n",
      "|    value_loss         | 0.000629     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 396           |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 89            |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.7         |\n",
      "|    explained_variance | -91.6         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | 1.05          |\n",
      "|    reward             | -0.0024820648 |\n",
      "|    std                | 10.7          |\n",
      "|    value_loss         | 0.000464      |\n",
      "-----------------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 680604.88\n",
      "total_reward: -319395.12\n",
      "total_cost: 59673.12\n",
      "total_trades: 6287\n",
      "Sharpe: -0.562\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | -0.722        |\n",
      "|    reward             | -0.0018058806 |\n",
      "|    std                | 11.2          |\n",
      "|    value_loss         | 0.000195      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 92            |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | 0.401         |\n",
      "|    reward             | -0.0063286843 |\n",
      "|    std                | 11.7          |\n",
      "|    value_loss         | 5.98e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 956478.90\n",
      "total_reward: -43521.10\n",
      "total_cost: 72261.10\n",
      "total_trades: 6775\n",
      "Sharpe: -0.087\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 93           |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.00909      |\n",
      "|    reward             | -0.006165345 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 7.35e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 94            |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.0511        |\n",
      "|    reward             | -0.0032201966 |\n",
      "|    std                | 12.8          |\n",
      "|    value_loss         | 4.4e-06       |\n",
      "-----------------------------------------\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1041594.48\n",
      "total_reward: 41594.48\n",
      "total_cost: 75181.52\n",
      "total_trades: 6864\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.219        |\n",
      "|    reward             | -0.007529545 |\n",
      "|    std                | 13.4         |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -60.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.16         |\n",
      "|    reward             | -0.007980827 |\n",
      "|    std                | 14.1         |\n",
      "|    value_loss         | 1.23e-05     |\n",
      "----------------------------------------\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1028836.37\n",
      "total_reward: 28836.37\n",
      "total_cost: 86861.63\n",
      "total_trades: 7420\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.195        |\n",
      "|    reward             | -0.012821709 |\n",
      "|    std                | 14.6         |\n",
      "|    value_loss         | 1.21e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 395         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -62         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | -0.00825014 |\n",
      "|    std                | 15.3        |\n",
      "|    value_loss         | 9.78e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -62.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | -0.307       |\n",
      "|    reward             | -0.010598578 |\n",
      "|    std                | 16.1         |\n",
      "|    value_loss         | 3.3e-05      |\n",
      "----------------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 922101.72\n",
      "total_reward: -77898.28\n",
      "total_cost: 84525.28\n",
      "total_trades: 7660\n",
      "Sharpe: -0.275\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -63.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.003219191 |\n",
      "|    std                | 16.9         |\n",
      "|    value_loss         | 1.44e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.17        |\n",
      "|    reward             | -0.009991151 |\n",
      "|    std                | 17.8         |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 933060.74\n",
      "total_reward: -66939.26\n",
      "total_cost: 92826.26\n",
      "total_trades: 8185\n",
      "Sharpe: -0.207\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 104          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.008782921 |\n",
      "|    std                | 18.7         |\n",
      "|    value_loss         | 5.72e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -65.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.377        |\n",
      "|    reward             | -0.012334613 |\n",
      "|    std                | 19.7         |\n",
      "|    value_loss         | 3.47e-05     |\n",
      "----------------------------------------\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 877797.60\n",
      "total_reward: -122202.40\n",
      "total_cost: 99432.40\n",
      "total_trades: 8589\n",
      "Sharpe: -0.328\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -66.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | -0.97        |\n",
      "|    reward             | -0.008410723 |\n",
      "|    std                | 20.6         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 8600          |\n",
      "|    time_elapsed       | 108           |\n",
      "|    total_timesteps    | 43000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8599          |\n",
      "|    policy_loss        | 0.488         |\n",
      "|    reward             | -0.0047607315 |\n",
      "|    std                | 21.8          |\n",
      "|    value_loss         | 7.12e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1021262.89\n",
      "total_reward: 21262.89\n",
      "total_cost: 103897.11\n",
      "total_trades: 9022\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 110           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -68           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 0.973         |\n",
      "|    reward             | -0.0094808545 |\n",
      "|    std                | 23            |\n",
      "|    value_loss         | 0.000298      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | 0.472        |\n",
      "|    reward             | -0.012571565 |\n",
      "|    std                | 24.2         |\n",
      "|    value_loss         | 4.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.4        |\n",
      "|    explained_variance | 0.638        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 0.804        |\n",
      "|    reward             | -0.021155957 |\n",
      "|    std                | 25.2         |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 790582.01\n",
      "total_reward: -209417.99\n",
      "total_cost: 110442.99\n",
      "total_trades: 9388\n",
      "Sharpe: -0.396\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 395         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -70         |\n",
      "|    explained_variance | -3.41       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | -0.06054416 |\n",
      "|    std                | 26.3        |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -70.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.547        |\n",
      "|    reward             | -0.008167794 |\n",
      "|    std                | 27.1         |\n",
      "|    value_loss         | 6.87e-05     |\n",
      "----------------------------------------\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 699517.92\n",
      "total_reward: -300482.08\n",
      "total_cost: 108640.08\n",
      "total_trades: 9460\n",
      "Sharpe: -0.409\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 116          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -0.215       |\n",
      "|    reward             | -0.003789871 |\n",
      "|    std                | 28.2         |\n",
      "|    value_loss         | 1.67e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.552        |\n",
      "|    reward             | -0.011297163 |\n",
      "|    std                | 29.3         |\n",
      "|    value_loss         | 7.01e-05     |\n",
      "----------------------------------------\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 691617.13\n",
      "total_reward: -308382.87\n",
      "total_cost: 119540.87\n",
      "total_trades: 9861\n",
      "Sharpe: -0.485\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.436        |\n",
      "|    reward             | -0.010963649 |\n",
      "|    std                | 30.5         |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 395         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -72.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.455       |\n",
      "|    reward             | -0.02014235 |\n",
      "|    std                | 31.9        |\n",
      "|    value_loss         | 5.49e-05    |\n",
      "---------------------------------------\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 896739.69\n",
      "total_reward: -103260.31\n",
      "total_cost: 126837.31\n",
      "total_trades: 10463\n",
      "Sharpe: -0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 9600          |\n",
      "|    time_elapsed       | 121           |\n",
      "|    total_timesteps    | 48000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9599          |\n",
      "|    policy_loss        | 0.448         |\n",
      "|    reward             | -0.0042691627 |\n",
      "|    std                | 33.3          |\n",
      "|    value_loss         | 5.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.0903      |\n",
      "|    reward             | -0.009895897 |\n",
      "|    std                | 34.9         |\n",
      "|    value_loss         | 1.91e-05     |\n",
      "----------------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1038850.32\n",
      "total_reward: 38850.32\n",
      "total_cost: 135087.68\n",
      "total_trades: 10580\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -74.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.224        |\n",
      "|    reward             | -0.009956244 |\n",
      "|    std                | 36.3         |\n",
      "|    value_loss         | 4.43e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 395          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.524       |\n",
      "|    reward             | -0.008845611 |\n",
      "|    std                | 38           |\n",
      "|    value_loss         | 6.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 395           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 126           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -76           |\n",
      "|    explained_variance | -0.0124       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | 0.611         |\n",
      "|    reward             | -0.0121755665 |\n",
      "|    std                | 39.7          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env=env_train) \n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ArAnGULyVVfK",
   "metadata": {
    "id": "ArAnGULyVVfK"
   },
   "source": [
    "## Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "TzU6JBAWVGPG",
   "metadata": {
    "id": "TzU6JBAWVGPG"
   },
   "outputs": [],
   "source": [
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE) \n",
    "trade[\"date\"] = trade[\"time\"]\n",
    "\n",
    "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True } \n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdg8qypiVSOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdg8qypiVSOn",
    "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 103, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1088615.34\n",
      "total_reward: 88615.34\n",
      "total_cost: 68.66\n",
      "total_trades: 28\n",
      "Sharpe: 1.285\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Ih4rdH3uVSo1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4rdH3uVSo1",
    "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_actions:             600000  600009  600016  600028  600030  600031  600036  600050  \\\n",
      "date                                                                         \n",
      "2019-08-01    1000    1000       0    1000    1000    1000    1000    1000   \n",
      "2019-08-01    1000    1000       0    1000    1000    1000    1000    1000   \n",
      "2019-08-02       0       0       0       0       0       0       0     300   \n",
      "2019-08-05       0       0       0       0       0       0       0       0   \n",
      "2019-08-06       0       0       0       0       0       0       0       0   \n",
      "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2019-12-24       0       0       0       0       0       0       0       0   \n",
      "2019-12-25       0       0       0       0       0       0       0       0   \n",
      "2019-12-26       0       0       0       0       0       0       0       0   \n",
      "2019-12-27       0       0       0       0       0       0       0       0   \n",
      "2019-12-30       0       0       0       0       0       0       0       0   \n",
      "\n",
      "            600104  600196  600276  600309  600519  600547  600570  \n",
      "date                                                                \n",
      "2019-08-01    1000       0    1000    1000       0    1000    1000  \n",
      "2019-08-01    1000       0    1000    1000       0    1000    1000  \n",
      "2019-08-02       0       0       0    1000       0    1000    1000  \n",
      "2019-08-05       0       0       0       0       0       0       0  \n",
      "2019-08-06       0       0       0       0       0       0       0  \n",
      "...            ...     ...     ...     ...     ...     ...     ...  \n",
      "2019-12-24       0       0       0       0       0       0       0  \n",
      "2019-12-25       0       0       0       0       0       0       0  \n",
      "2019-12-26       0       0       0       0       0       0       0  \n",
      "2019-12-27       0       0       0       0       0       0       0  \n",
      "2019-12-30       0       0       0       0       0       0       0  \n",
      "\n",
      "[103 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_actions.to_csv(\"action.csv\", index=False) \n",
    "print(f\"df_actions: {df_actions}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "l7X1KIaVWUYp",
   "metadata": {
    "id": "l7X1KIaVWUYp"
   },
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cbf6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补充time列\n",
    "df_account_value.time = df_account_value.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e86f913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对齐两个DataFrame数据\n",
    "trade[\"date\"] = pd.to_datetime(trade[\"date\"])\n",
    "\n",
    "account_dates = df_account_value['date'].unique()\n",
    "trade_filtered = trade[trade['date'].isin(account_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f79591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "date=%{x}<br>account_value=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          "2019-08-01T00:00:00",
          "2019-08-02T00:00:00",
          "2019-08-05T00:00:00",
          "2019-08-06T00:00:00",
          "2019-08-07T00:00:00",
          "2019-08-08T00:00:00",
          "2019-08-09T00:00:00",
          "2019-08-12T00:00:00",
          "2019-08-13T00:00:00",
          "2019-08-14T00:00:00",
          "2019-08-15T00:00:00",
          "2019-08-16T00:00:00",
          "2019-08-19T00:00:00",
          "2019-08-20T00:00:00",
          "2019-08-21T00:00:00",
          "2019-08-22T00:00:00",
          "2019-08-23T00:00:00",
          "2019-08-26T00:00:00",
          "2019-08-27T00:00:00",
          "2019-08-28T00:00:00",
          "2019-08-29T00:00:00",
          "2019-08-30T00:00:00",
          "2019-09-02T00:00:00",
          "2019-09-03T00:00:00",
          "2019-09-04T00:00:00",
          "2019-09-05T00:00:00",
          "2019-09-06T00:00:00",
          "2019-09-09T00:00:00",
          "2019-09-10T00:00:00",
          "2019-09-11T00:00:00",
          "2019-09-12T00:00:00",
          "2019-09-16T00:00:00",
          "2019-09-17T00:00:00",
          "2019-09-18T00:00:00",
          "2019-09-19T00:00:00",
          "2019-09-20T00:00:00",
          "2019-09-23T00:00:00",
          "2019-09-24T00:00:00",
          "2019-09-25T00:00:00",
          "2019-09-26T00:00:00",
          "2019-09-27T00:00:00",
          "2019-09-30T00:00:00",
          "2019-10-08T00:00:00",
          "2019-10-09T00:00:00",
          "2019-10-10T00:00:00",
          "2019-10-11T00:00:00",
          "2019-10-14T00:00:00",
          "2019-10-15T00:00:00",
          "2019-10-16T00:00:00",
          "2019-10-17T00:00:00",
          "2019-10-18T00:00:00",
          "2019-10-21T00:00:00",
          "2019-10-22T00:00:00",
          "2019-10-23T00:00:00",
          "2019-10-24T00:00:00",
          "2019-10-25T00:00:00",
          "2019-10-28T00:00:00",
          "2019-10-29T00:00:00",
          "2019-10-30T00:00:00",
          "2019-10-31T00:00:00",
          "2019-11-01T00:00:00",
          "2019-11-04T00:00:00",
          "2019-11-05T00:00:00",
          "2019-11-06T00:00:00",
          "2019-11-07T00:00:00",
          "2019-11-08T00:00:00",
          "2019-11-11T00:00:00",
          "2019-11-12T00:00:00",
          "2019-11-13T00:00:00",
          "2019-11-14T00:00:00",
          "2019-11-15T00:00:00",
          "2019-11-18T00:00:00",
          "2019-11-19T00:00:00",
          "2019-11-20T00:00:00",
          "2019-11-21T00:00:00",
          "2019-11-22T00:00:00",
          "2019-11-25T00:00:00",
          "2019-11-26T00:00:00",
          "2019-11-27T00:00:00",
          "2019-11-28T00:00:00",
          "2019-11-29T00:00:00",
          "2019-12-02T00:00:00",
          "2019-12-03T00:00:00",
          "2019-12-04T00:00:00",
          "2019-12-05T00:00:00",
          "2019-12-06T00:00:00",
          "2019-12-09T00:00:00",
          "2019-12-10T00:00:00",
          "2019-12-11T00:00:00",
          "2019-12-12T00:00:00",
          "2019-12-13T00:00:00",
          "2019-12-16T00:00:00",
          "2019-12-17T00:00:00",
          "2019-12-18T00:00:00",
          "2019-12-19T00:00:00",
          "2019-12-20T00:00:00",
          "2019-12-23T00:00:00",
          "2019-12-24T00:00:00",
          "2019-12-25T00:00:00",
          "2019-12-26T00:00:00",
          "2019-12-27T00:00:00",
          "2019-12-30T00:00:00",
          "2019-12-31T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          999970.818301,
          994412.0165130001,
          980901.3355179001,
          975043.3355179001,
          977654.3355179001,
          996313.3355179001,
          989525.3355179001,
          1003121.3355179001,
          1001421.3355179001,
          1005424.3355179001,
          1015060.3355179001,
          1024437.3355179001,
          1050816.3355179,
          1008532.3355179001,
          1006803.3355179001,
          1005613.3355179001,
          1024613.3355179001,
          1015729.3355179001,
          1042540.3355179001,
          1039667.3355179001,
          1039943.3355179001,
          1041593.3355179001,
          1058053.3355179,
          1052295.3355179,
          1060249.3355179,
          1075867.3355179,
          1081875.3355179,
          1088397.3355179,
          1081995.3355179,
          1063997.3355179,
          1071707.3355179,
          1073062.3355179,
          1054191.3355179,
          1054592.3355179,
          1055683.3355179,
          1056285.3355179,
          1043071.3355179001,
          1044205.3355179001,
          1040757.3355179001,
          1021397.3355179001,
          1022672.3355179001,
          1015401.3355179001,
          1009357.3355179001,
          1011386.3355179001,
          1032055.3355179001,
          1040164.3355179001,
          1043213.3355179001,
          1031265.3355179001,
          1031058.3355179001,
          1031005.3355179001,
          1011945.3355179001,
          1008286.3355179001,
          1014072.3355179001,
          1007944.3355179001,
          998014.3355179001,
          1023933.3355179001,
          1056675.3355179,
          1043598.3355179001,
          1042767.3355179001,
          1032940.3355179001,
          1045686.3355179001,
          1053686.3355179,
          1056422.3355179,
          1047022.3355179001,
          1047953.3355179001,
          1045426.3355179001,
          1030181.3355179001,
          1027040.3355179001,
          1035533.3355179001,
          1040593.3355179001,
          1024713.3355179001,
          1028635.3355179001,
          1042992.3355179001,
          1043233.3355179001,
          1037037.3355179001,
          1028815.3355179001,
          1026122.3355179001,
          1032877.3355179001,
          1029832.3355179001,
          1031387.3355179001,
          1013711.3355179001,
          1015517.3355179001,
          1014264.3355179001,
          1017871.3355179001,
          1031902.3355179001,
          1037933.3355179001,
          1031126.3355179001,
          1048066.3355179001,
          1047988.3355179001,
          1047593.3355179001,
          1065820.3355179,
          1069054.3355179,
          1076212.3355179,
          1069650.3355179,
          1067032.3355179,
          1066692.3355179,
          1056808.3355179,
          1059568.3355179,
          1059674.3355179,
          1062707.3355179,
          1062102.3355179,
          1080535.3355179,
          1088615.3355179
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Account Value"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "account_value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(df_account_value, x=\"date\", y=\"account_value\", title=\"Account Value\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "China_A_share_market_tushare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
